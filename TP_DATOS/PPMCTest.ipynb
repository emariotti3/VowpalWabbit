{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PPMC_ORDER = 4\n",
    "ID = 0\n",
    "TEXT = 9\n",
    "PREDICTION = 6\n",
    "\n",
    "fieldnames = [\"Id\", \"ProductId\", \"UserId\", \"ProfileName\", \"HelpfulnessNumerator\",\n",
    "            \"HelpfulnessDenominator\", \"Prediction\", \"Time\", \"Summary\", \"Text\"]\n",
    "\n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')\n",
    "import csv\n",
    "from PPMC import PPMC\n",
    "\n",
    "#text = \"i got them in a very timely manner and they're all very large and green. there seems to be an inordinate amount of the seeds e out a weird beige color, but it still tastes great and is a much better deal than any of the indian markets in town. cheers to frontier.\"\n",
    "\n",
    "trainRDD = sc.textFile(\"train_sin_repeticiones.csv\", minPartitions=None, use_unicode=False).mapPartitions(lambda x: csv.reader(x))\n",
    "trainRDD = trainRDD.filter(lambda line: line[ID] != \"Id\")\n",
    "\n",
    "trainRDD = trainRDD.sample(False, 0.01)\n",
    "\n",
    "#se podria hacer un map antes que limpie el texto\n",
    "#comprimo todo el train con ppmc\n",
    "trainRDD = trainRDD.map(lambda line: (line[PREDICTION], (PPMC(PPMC_ORDER), line[TEXT])))\n",
    "\n",
    "trainRDD = trainRDD.map(lambda line: (line[0], (line[1][0], 1, line[1][0].compress(line[1][1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l=[0]\n",
    "\n",
    "def foo(value1, value2):\n",
    "    print l[0]\n",
    "    l[0]+=1\n",
    "    return (value1[0]+value2[0], value1[1]+value2[1])\n",
    "\n",
    "test_prediction = open(\"test_prediction\", \"w\")\n",
    "writer = csv.DictWriter(test_prediction, fieldnames=fieldnames)\n",
    "writer.writeheader()\n",
    "\n",
    "with open(\"test.csv\", \"r\") as test:\n",
    "    reader = csv.DictReader(test)\n",
    "    for row in reader:\n",
    "        text = row[\"Text\"]\n",
    "        #comprimo el texto de prueba con los modelos de todo el rdd\n",
    "        testRDD = trainRDD.map(lambda line: (line[0], (len(line[1][0].compress(text)), line[1][1])))\n",
    "        testRDD = testRDD.reduceByKey(lambda value1, value2: foo(value1, value2))\n",
    "        testRDD = testRDD.reduce(lambda line1, line2: line1 if line1[1][0]/line1[1][1] < line2[1][0]/line2[1][1] else line2)\n",
    "        row[\"Prediction\"] = testRDD[0]\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
